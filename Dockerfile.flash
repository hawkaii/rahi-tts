FROM pytorch/pytorch:2.4.0-cuda12.1-cudnn9-devel

# Basic tools
RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Flash Attention 2 first (requires compilation)
RUN pip install --no-cache-dir "flash-attn>=2.3.0"

# Install transformers 4.48.0 which has better Flash Attention support
RUN pip install --no-cache-dir "transformers==4.48.0"

# Clone parler-tts and modify its dependencies to accept transformers 4.48.0
RUN git clone https://github.com/huggingface/parler-tts.git /tmp/parler-tts && \
    cd /tmp/parler-tts && \
    # Modify setup.py to allow transformers 4.48.0
    sed -i 's/transformers>=4.46.1,<=4.46.1/transformers>=4.46.1,<=4.48.0/' setup.py && \
    pip install --no-cache-dir -e . && \
    cd /app && \
    rm -rf /tmp/parler-tts

# Install remaining dependencies
RUN pip install --no-cache-dir \
    fastapi \
    uvicorn \
    soundfile \
    scipy

COPY main.py .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
